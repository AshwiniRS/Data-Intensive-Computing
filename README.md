# Data-Intensive-Computing
It comprises of DIC projects implemented in Jupyter notebook or R Studio in R language.

<B>Lab 1 : Data Clients and Information Servers </b></br>
GOALS:</br>
 1. Install a work environment for carrying out various activities of the data science process. <br>
 2. Understand and implement Application Programming Interface (API) based programmatic data collection from popular (/public) data sources (Data clients).<br>
 3. Process the data collected for extracting basic information.<br>
 4. Serve the information extracted through simple applications and visualization (Information servers).<br>

<b> Lab 2 : Data Cleaning and Munging</b><br>
GOALS:<br>
  1. Convert data in various format into a form that is convenient for in-memory operations.
     Transform from external storage formats such as xml, sqllite into a common external format, comma separated value (.csv) convenient for exploratory data analysis using R. This allows for
      easy reading of data into the memory as data frames.<br>
  2. Extract (data munging) useful data from raw data collected by real survey instruments. You will use the actual survey document in interpreting the survey results.<br>
  3. Repurpose data from a popular domain (such as sports) for consumption by different genre of applications.<br>
  4. Transform data using operations such as grouping, categorization and binning to stage them for in-memory analysis. (R is optimized to work well with in-memory data.)<br>
  5. Document data cleaning steps using Markdown, a text-based HTML authoring format. This is an essential step in “reproducible research” and is offered within Jupyter platform.<br>
  6. Learn and understand the scientific data collection process, surveys, and nature of raw data and the need and motivation for cleaning and munging the data.<br>

<b> Lab 3 : Algorithms and Models for Data Analysis, Learning and Prediction.</b><br>
GOALS:<br>
  1. Decide on the algorithms that will be used in solving the problem based on the data characteristics and the attributes of the problems.<br>
  2. Learn to apply algorithms: linear regression, K-NN and K-means, which algorithm to use and why and when.<br>
  3. Make valid and reasonable assumptions about the variables (features) of a problem, goodness of a model fit, metrics for evaluation of errors, outliers, scaling, and choosing appropriate data ranges for the computation.<br>
  4. Choose the parameters for prediction based on experimentation (repeated trials) and acceptable values of error rates. Document the experimentation process and the rationale.<br>
  5. Plot the outcomes for easy visualization of data analysis.<br>
  6. Interpret the results to enable decision making.<br>
  
  
  For more information about the activities carried out in each lab, please check the lab ddescriptions placed in each lab folder. 
